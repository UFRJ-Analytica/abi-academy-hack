{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1c6b7f-d73d-4622-838f-b32e0294ce17",
   "metadata": {},
   "source": [
    "# Modelo Pre Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cbb9b5-935e-45b9-807c-b80f79478e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-27 20:44:10--  https://pretrained-nmt-models.s3-us-west-2.amazonaws.com/uncorpus-fren-subword-transformer-model_step_200000.pt\n",
      "Resolving pretrained-nmt-models.s3-us-west-2.amazonaws.com (pretrained-nmt-models.s3-us-west-2.amazonaws.com)... 52.218.252.65\n",
      "Connecting to pretrained-nmt-models.s3-us-west-2.amazonaws.com (pretrained-nmt-models.s3-us-west-2.amazonaws.com)|52.218.252.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1477612795 (1,4G) [binary/octet-stream]\n",
      "Saving to: ‘uncorpus-fren-subword-transformer-model_step_200000.pt’\n",
      "\n",
      "uncorpus-fren-subwo 100%[===================>]   1,38G  3,84MB/s    in 5m 35s  \n",
      "\n",
      "2021-10-27 20:49:46 (4,20 MB/s) - ‘uncorpus-fren-subword-transformer-model_step_200000.pt’ saved [1477612795/1477612795]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pretrained-nmt-models.s3-us-west-2.amazonaws.com/uncorpus-fren-subword-transformer-model_step_200000.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec88bf45-a50a-46cf-8c3d-d3e2ccbdc356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ronald/anaconda3/lib/python3.8/site-packages (21.3)\n",
      "Collecting pip\n",
      "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 2.5 MB/s            \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.3\n",
      "    Uninstalling pip-21.3:\n",
      "      Successfully uninstalled pip-21.3\n",
      "Successfully installed pip-21.3.1\n",
      "Requirement already satisfied: ctranslate2 in /home/ronald/anaconda3/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in /home/ronald/anaconda3/lib/python3.8/site-packages (from ctranslate2) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install ctranslate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3278bd-cfa4-487e-94ca-3258eb5bde11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ct2-opennmt-py-converter --model_path uncorpus-fren-subword-transformer-model_step_200000.pt --output_dir ende_ctranslate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341965f2-f724-458f-9c39-b7dc9ffbf92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-27 20:51:03--  https://un-corpus.s3-us-west-2.amazonaws.com/un-subword-model.tar.gz\n",
      "Resolving un-corpus.s3-us-west-2.amazonaws.com (un-corpus.s3-us-west-2.amazonaws.com)... 52.218.244.81\n",
      "Connecting to un-corpus.s3-us-west-2.amazonaws.com (un-corpus.s3-us-west-2.amazonaws.com)|52.218.244.81|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2977796 (2,8M) [application/x-tar]\n",
      "Saving to: ‘un-subword-model.tar.gz’\n",
      "\n",
      "un-subword-model.ta 100%[===================>]   2,84M  1,60MB/s    in 1,8s    \n",
      "\n",
      "2021-10-27 20:51:07 (1,60 MB/s) - ‘un-subword-model.tar.gz’ saved [2977796/2977796]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://un-corpus.s3-us-west-2.amazonaws.com/un-subword-model.tar.gz\n",
    "!mkdir sentence-piece-model\n",
    "!tar xf un-subword-model.tar.gz -C sentence-piece-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a499373-c8d1-4a97-86cf-42bd49a2f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ronald/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4ec2ab-3db6-4e90-aae0-412e57c41224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import ctranslate2\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "\n",
    "def tokenize(text, sp_source_model):\n",
    "    \"\"\"Use SentencePiece model to tokenize a sentence\n",
    "    Args:\n",
    "        text (str): A sentence to tokenize\n",
    "        sp_source_model (str): The path to the SentencePiece source model\n",
    "    Returns:\n",
    "        List of of tokens of the text.\n",
    "    \"\"\"\n",
    "\n",
    "    sp = spm.SentencePieceProcessor(sp_source_model)\n",
    "    tokens = sp.encode(text, out_type=str)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def detokenize(text, sp_target_model):\n",
    "    \"\"\"Use SentencePiece model to detokenize a sentence\n",
    "    Args:\n",
    "        text (list(str)): A sentence to tokenize\n",
    "        sp_target_model (str): The path to the SentencePiece target model\n",
    "    Returns:\n",
    "        String of the detokenized text.\n",
    "    \"\"\"\n",
    "\n",
    "    sp = spm.SentencePieceProcessor(sp_target_model)\n",
    "    translation = sp.decode(text)\n",
    "    return translation\n",
    "\n",
    "\n",
    "def translate(source, ct_model, sp_source_model, sp_target_model, device=\"cpu\"):\n",
    "    \"\"\"Use CTranslate model to translate a sentence\n",
    "    Args:\n",
    "        source (str): A source sentence to translate\n",
    "        ct_model (str): The path to the CTranslate model\n",
    "        sp_source_model (str): The path to the SentencePiece source model\n",
    "        sp_target_model (str): The path to the SentencePiece target model\n",
    "        device (str): \"cpu\" (default) or \"cuda\"\n",
    "    Returns:\n",
    "        Translation of the source text.\n",
    "    \"\"\"\n",
    "\n",
    "    translator = ctranslate2.Translator(ct_model, device)\n",
    "    source_sentences = sent_tokenize(source)\n",
    "    source_tokenized = tokenize(source_sentences, sp_source_model)\n",
    "    translations = translator.translate_batch(source_tokenized, replace_unknowns=True)\n",
    "    translations = [translation[0][\"tokens\"] for translation in translations]\n",
    "    translations_detokenized = detokenize(translations, sp_target_model)\n",
    "    translation = \" \".join(translations_detokenized)\n",
    "\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451bec51-4b2e-45be-ac56-12e4fc688b50",
   "metadata": {},
   "source": [
    "### Testando a Tradução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38277839-1634-4a47-bca4-fd82ebe3009e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a large proportion of these accidents occur at these black spots , which some member states already identify and identify .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = \"Une grande partie de ces accidents se produisent à ces points noirs que certains États membres identifient et répertorient déjà.\"\n",
    "src = str.lower(src)\n",
    "model = \"ende_ctranslate2\"\n",
    "sp_source_model = \"sentence-piece-model/source.model\"\n",
    "sp_target_model = \"sentence-piece-model/target.model\"\n",
    "\n",
    "translate(src, model, sp_source_model, sp_target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44464b5e-e2dd-48c2-a76c-752acb3da3fd",
   "metadata": {},
   "source": [
    "# Refinamento do Modelo usando os dados de 'dados-fr-en'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d76bb3-2c97-4607-ac09-ff8885774bf5",
   "metadata": {},
   "source": [
    "São os dados que a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4533d55-ad8e-4601-984e-a8c1a37d3428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ronald/anaconda3/lib/python3.8/site-packages (21.3.1)\n",
      "Requirement already satisfied: OpenNMT-py in /home/ronald/anaconda3/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (1.9.1)\n",
      "Requirement already satisfied: tensorboard>=2.3 in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (2.7.0)\n",
      "Requirement already satisfied: pyonmttok<2,>=1.23 in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (1.29.0)\n",
      "Requirement already satisfied: configargparse in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (1.5.3)\n",
      "Requirement already satisfied: torchtext==0.5.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (0.5.0)\n",
      "Requirement already satisfied: pyyaml in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (5.4.1)\n",
      "Requirement already satisfied: flask in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (1.1.2)\n",
      "Requirement already satisfied: waitress in /home/ronald/anaconda3/lib/python3.8/site-packages (from OpenNMT-py) (2.0.0)\n",
      "Requirement already satisfied: requests in /home/ronald/anaconda3/lib/python3.8/site-packages (from torchtext==0.5.0->OpenNMT-py) (2.25.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ronald/anaconda3/lib/python3.8/site-packages (from torchtext==0.5.0->OpenNMT-py) (0.1.96)\n",
      "Requirement already satisfied: six in /home/ronald/anaconda3/lib/python3.8/site-packages (from torchtext==0.5.0->OpenNMT-py) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /home/ronald/anaconda3/lib/python3.8/site-packages (from torchtext==0.5.0->OpenNMT-py) (4.62.0)\n",
      "Requirement already satisfied: numpy in /home/ronald/anaconda3/lib/python3.8/site-packages (from torchtext==0.5.0->OpenNMT-py) (1.19.5)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.41.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ronald/.local/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (58.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (2.3.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.14.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (3.17.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ronald/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (3.3.4)\n",
      "Requirement already satisfied: typing_extensions in /home/ronald/anaconda3/lib/python3.8/site-packages (from torch>=1.6.0->OpenNMT-py) (3.7.4.3)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from flask->OpenNMT-py) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/ronald/anaconda3/lib/python3.8/site-packages (from flask->OpenNMT-py) (2.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from flask->OpenNMT-py) (7.1.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ronald/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.10.1->flask->OpenNMT-py) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ronald/.local/lib/python3.8/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2020.6.20)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2.10)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ronald/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install OpenNMT-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1b0cd2-bd4f-4f0f-b329-1744b58dc555",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xai-image-widget\n",
      "  Downloading xai_image_widget-0.1.0-py2.py3-none-any.whl (18.8 MB)\n",
      "     |████████████████████████████████| 18.8 MB 5.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from xai-image-widget) (7.6.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (5.1.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/ronald/.local/lib/python3.8/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (7.28.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/ronald/.local/lib/python3.8/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ronald/.local/lib/python3.8/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (5.1.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/ronald/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/ronald/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/ronald/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (1.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/ronald/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/ronald/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (7.0.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (58.2.0)\n",
      "Requirement already satisfied: decorator in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (3.0.20)\n",
      "Requirement already satisfied: pygments in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/ronald/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /home/ronald/.local/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->xai-image-widget) (4.8.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->xai-image-widget) (3.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (6.4.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ronald/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.8.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->xai-image-widget) (21.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->xai-image-widget) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->xai-image-widget) (0.17.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ronald/.local/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/ronald/.local/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (1.5.1)\n",
      "Requirement already satisfied: entrypoints in /home/ronald/.local/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/ronald/.local/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (22.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (2.11.3)\n",
      "Requirement already satisfied: nbconvert in /home/ronald/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (6.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/ronald/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in /home/ronald/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.11.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ronald/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.9.4)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (1.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ronald/.local/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ronald/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (1.14.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ronald/anaconda3/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (2.0.1)\n",
      "Requirement already satisfied: defusedxml in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.7.1)\n",
      "Requirement already satisfied: bleach in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (4.0.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (1.4.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.1.2)\n",
      "Requirement already satisfied: testpath in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.5.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycparser in /home/ronald/anaconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (2.20)\n",
      "Requirement already satisfied: async-generator in /home/ronald/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (1.10)\n",
      "Requirement already satisfied: packaging in /home/ronald/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (21.0)\n",
      "Requirement already satisfied: webencodings in /home/ronald/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-image-widget) (2.4.7)\n",
      "Installing collected packages: xai-image-widget\n",
      "Successfully installed xai-image-widget-0.1.0\n",
      "Collecting tangled-up-in-unicode==0.1.0\n",
      "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
      "     |████████████████████████████████| 3.1 MB 2.9 MB/s            \n",
      "\u001b[?25hInstalling collected packages: tangled-up-in-unicode\n",
      "Successfully installed tangled-up-in-unicode-0.1.0\n",
      "Collecting google-api-core[grpc]\n",
      "  Downloading google_api_core-2.2.0-py2.py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 570 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /home/ronald/.local/lib/python3.8/site-packages (from google-api-core[grpc]) (58.2.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core[grpc]) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core[grpc]) (2.3.0)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "     |████████████████████████████████| 198 kB 2.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core[grpc]) (3.17.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core[grpc]) (1.41.0)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2\n",
      "  Downloading grpcio_status-1.41.1-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]) (4.7.2)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]) (1.15.0)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "     |████████████████████████████████| 3.9 MB 3.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ronald/.local/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]) (2020.6.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ronald/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]) (0.4.8)\n",
      "Installing collected packages: grpcio, googleapis-common-protos, grpcio-status, google-api-core\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.41.0\n",
      "    Uninstalling grpcio-1.41.0:\n",
      "      Successfully uninstalled grpcio-1.41.0\n",
      "Successfully installed google-api-core-2.2.0 googleapis-common-protos-1.53.0 grpcio-1.41.1 grpcio-status-1.41.1\n",
      "Collecting google-api-python-client==1.8.0\n",
      "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 315 kB/s             \n",
      "\u001b[?25hCollecting google-api-core<2dev,>=1.13.0\n",
      "  Downloading google_api_core-1.31.3-py2.py3-none-any.whl (93 kB)\n",
      "     |████████████████████████████████| 93 kB 308 kB/s            \n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-python-client==1.8.0) (1.15.0)\n",
      "Collecting httplib2<1dev,>=0.9.2\n",
      "  Downloading httplib2-0.20.1-py3-none-any.whl (96 kB)\n",
      "     |████████████████████████████████| 96 kB 735 kB/s            \n",
      "\u001b[?25hCollecting uritemplate<4dev,>=3.0.0\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-python-client==1.8.0) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ronald/.local/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (58.2.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (21.0)\n",
      "Requirement already satisfied: pytz in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (2021.1)\n",
      "Collecting google-auth>=1.4.1\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 4.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (2.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (1.53.0)\n",
      "Requirement already satisfied: protobuf<3.18.0,>=3.12.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (3.17.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ronald/anaconda3/lib/python3.8/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0) (4.2.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ronald/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ronald/.local/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ronald/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0) (2.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: httplib2, google-auth, uritemplate, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.3.0\n",
      "    Uninstalling google-auth-2.3.0:\n",
      "      Successfully uninstalled google-auth-2.3.0\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 2.2.0\n",
      "    Uninstalling google-api-core-2.2.0:\n",
      "      Successfully uninstalled google-api-core-2.2.0\n",
      "Successfully installed google-api-core-1.31.3 google-api-python-client-1.8.0 google-auth-1.35.0 google-auth-httplib2-0.1.0 httplib2-0.20.1 uritemplate-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xai-image-widget\n",
    "!pip install tangled-up-in-unicode==0.1.0\n",
    "!pip install google-api-core[grpc]\n",
    "!pip install google-api-python-client==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d0d4ee-7cfb-433d-84bc-a3dbfd3e8100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2021-10-25 16:26:23,287 INFO] Counter vocab from 10000 samples.\n",
      "[2021-10-25 16:26:23,287 INFO] Build vocab on 10000 transformed examples/corpus.\n",
      "[2021-10-25 16:26:23,296 INFO] corpus_1's transforms: TransformPipe()\n",
      "[2021-10-25 16:26:23,602 INFO] Counters src:24995\n",
      "[2021-10-25 16:26:23,602 INFO] Counters tgt:35816\n"
     ]
    }
   ],
   "source": [
    "#!onmt_build_vocab -config toy_en_de.yaml -n_sample 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d47b0-82b0-4590-914d-6081ca406fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-10-27 21:15:49,795 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
      "[2021-10-27 21:15:49,795 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2021-10-27 21:15:49,795 INFO] Parsed 1 corpora from -data.\n",
      "[2021-10-27 21:15:49,795 INFO] Loading checkpoint from uncorpus-fren-subword-transformer-model_step_200000.pt\n",
      "[2021-10-27 21:15:55,316 INFO] Loading fields from checkpoint...\n",
      "[2021-10-27 21:15:55,316 INFO]  * src vocab size = 50002\n",
      "[2021-10-27 21:15:55,317 INFO]  * tgt vocab size = 50004\n",
      "[2021-10-27 21:15:55,319 INFO] Building model...\n",
      "[2021-10-27 21:15:58,286 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(50002, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(50004, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=50004, bias=True)\n",
      "    (1): Cast()\n",
      "    (2): LogSoftmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "[2021-10-27 21:15:58,290 INFO] encoder: 44516352\n",
      "[2021-10-27 21:15:58,291 INFO] decoder: 76479316\n",
      "[2021-10-27 21:15:58,291 INFO] * number of parameters: 120995668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-10-27 21:15:59,285 INFO] Starting training on CPU, could be very slow\n",
      "[2021-10-27 21:15:59,285 INFO] Start training loop without validation...\n",
      "[2021-10-27 21:15:59,285 INFO] corpus_1's transforms: TransformPipe()\n",
      "[2021-10-27 21:15:59,285 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2021-10-27 21:16:00,021 WARNING] Empty line exists in corpus_1#549.\n",
      "[2021-10-27 21:16:00,040 WARNING] Empty line exists in corpus_1#1487.\n",
      "[2021-10-27 21:16:00,044 WARNING] Empty line exists in corpus_1#1846.\n",
      "[2021-10-27 21:16:00,044 WARNING] Empty line exists in corpus_1#1852.\n",
      "[2021-10-27 21:16:00,045 WARNING] Empty line exists in corpus_1#1889.\n",
      "[2021-10-27 21:16:00,047 WARNING] Empty line exists in corpus_1#2077.\n",
      "[2021-10-27 21:16:00,064 WARNING] Empty line exists in corpus_1#3256.\n",
      "[2021-10-27 21:16:00,116 WARNING] Empty line exists in corpus_1#4142.\n",
      "[2021-10-27 21:16:00,130 WARNING] Empty line exists in corpus_1#4909.\n",
      "[2021-10-27 21:16:00,143 WARNING] Empty line exists in corpus_1#5577.\n",
      "[2021-10-27 21:16:00,172 WARNING] Empty line exists in corpus_1#6169.\n",
      "[2021-10-27 21:16:00,206 WARNING] Empty line exists in corpus_1#6746.\n",
      "[2021-10-27 21:16:00,206 WARNING] Empty line exists in corpus_1#6747.\n",
      "[2021-10-27 21:16:00,231 WARNING] Empty line exists in corpus_1#7758.\n",
      "[2021-10-27 21:16:00,233 WARNING] Empty line exists in corpus_1#7862.\n",
      "[2021-10-27 21:16:00,279 WARNING] Empty line exists in corpus_1#9188.\n",
      "[2021-10-27 21:16:00,286 WARNING] Empty line exists in corpus_1#9571.\n",
      "[2021-10-27 21:16:00,288 WARNING] Empty line exists in corpus_1#9664.\n",
      "[2021-10-27 21:16:00,289 WARNING] Empty line exists in corpus_1#9709.\n",
      "[2021-10-27 21:16:00,292 WARNING] Empty line exists in corpus_1#9817.\n",
      "[2021-10-27 21:16:00,340 WARNING] Empty line exists in corpus_1#10406.\n",
      "[2021-10-27 21:16:00,341 WARNING] Empty line exists in corpus_1#10407.\n",
      "[2021-10-27 21:16:00,341 WARNING] Empty line exists in corpus_1#10409.\n",
      "[2021-10-27 21:16:00,349 WARNING] Empty line exists in corpus_1#10757.\n",
      "[2021-10-27 21:16:00,349 WARNING] Empty line exists in corpus_1#10758.\n",
      "[2021-10-27 21:16:00,349 WARNING] Empty line exists in corpus_1#10773.\n",
      "[2021-10-27 21:16:00,349 WARNING] Empty line exists in corpus_1#10774.\n",
      "[2021-10-27 21:16:00,349 WARNING] Empty line exists in corpus_1#10776.\n",
      "[2021-10-27 21:16:00,349 WARNING] Empty line exists in corpus_1#10789.\n",
      "[2021-10-27 21:16:00,350 WARNING] Empty line exists in corpus_1#10801.\n",
      "[2021-10-27 21:16:00,350 WARNING] Empty line exists in corpus_1#10877.\n",
      "[2021-10-27 21:16:00,350 WARNING] Empty line exists in corpus_1#10878.\n",
      "[2021-10-27 21:16:00,357 WARNING] Empty line exists in corpus_1#11219.\n",
      "[2021-10-27 21:16:00,369 WARNING] Empty line exists in corpus_1#11255.\n",
      "[2021-10-27 21:16:00,397 WARNING] Empty line exists in corpus_1#12352.\n",
      "[2021-10-27 21:16:00,397 WARNING] Empty line exists in corpus_1#12353.\n",
      "[2021-10-27 21:16:00,403 WARNING] Empty line exists in corpus_1#12829.\n",
      "[2021-10-27 21:16:00,410 WARNING] Empty line exists in corpus_1#13132.\n",
      "[2021-10-27 21:16:00,411 WARNING] Empty line exists in corpus_1#13199.\n",
      "[2021-10-27 21:16:00,411 WARNING] Empty line exists in corpus_1#13220.\n",
      "[2021-10-27 21:16:00,466 WARNING] Empty line exists in corpus_1#13302.\n",
      "[2021-10-27 21:16:00,557 WARNING] Empty line exists in corpus_1#15062.\n",
      "[2021-10-27 21:16:00,569 WARNING] Empty line exists in corpus_1#15892.\n",
      "[2021-10-27 21:16:00,569 WARNING] Empty line exists in corpus_1#15949.\n",
      "[2021-10-27 21:16:00,570 WARNING] Empty line exists in corpus_1#16007.\n",
      "[2021-10-27 21:16:00,612 WARNING] Empty line exists in corpus_1#16270.\n",
      "[2021-10-27 21:16:00,615 WARNING] Empty line exists in corpus_1#16392.\n",
      "[2021-10-27 21:16:00,615 WARNING] Empty line exists in corpus_1#16398.\n",
      "[2021-10-27 21:16:00,615 WARNING] Empty line exists in corpus_1#16408.\n",
      "[2021-10-27 21:16:00,616 WARNING] Empty line exists in corpus_1#16410.\n",
      "[2021-10-27 21:16:00,620 WARNING] Empty line exists in corpus_1#16636.\n",
      "[2021-10-27 21:16:00,620 WARNING] Empty line exists in corpus_1#16638.\n",
      "[2021-10-27 21:16:00,620 WARNING] Empty line exists in corpus_1#16641.\n",
      "[2021-10-27 21:16:00,658 WARNING] Empty line exists in corpus_1#17882.\n",
      "[2021-10-27 21:16:00,659 WARNING] Empty line exists in corpus_1#17897.\n",
      "[2021-10-27 21:16:00,659 WARNING] Empty line exists in corpus_1#17898.\n",
      "[2021-10-27 21:16:00,659 WARNING] Empty line exists in corpus_1#17899.\n",
      "[2021-10-27 21:16:00,659 WARNING] Empty line exists in corpus_1#17900.\n",
      "[2021-10-27 21:16:00,808 WARNING] Empty line exists in corpus_1#18114.\n",
      "[2021-10-27 21:16:00,819 WARNING] Empty line exists in corpus_1#18413.\n",
      "[2021-10-27 21:16:00,821 WARNING] Empty line exists in corpus_1#18661.\n",
      "[2021-10-27 21:16:00,822 WARNING] Empty line exists in corpus_1#18699.\n",
      "[2021-10-27 21:16:00,826 WARNING] Empty line exists in corpus_1#19130.\n",
      "[2021-10-27 21:16:00,962 WARNING] Empty line exists in corpus_1#20447.\n",
      "[2021-10-27 21:16:01,001 WARNING] Empty line exists in corpus_1#21100.\n",
      "[2021-10-27 21:16:01,002 WARNING] Empty line exists in corpus_1#21101.\n",
      "[2021-10-27 21:16:01,043 WARNING] Empty line exists in corpus_1#22080.\n",
      "[2021-10-27 21:16:01,057 WARNING] Empty line exists in corpus_1#22904.\n",
      "[2021-10-27 21:16:01,087 WARNING] Empty line exists in corpus_1#23991.\n",
      "[2021-10-27 21:16:01,096 WARNING] Empty line exists in corpus_1#24647.\n",
      "[2021-10-27 21:16:01,172 WARNING] Empty line exists in corpus_1#25091.\n",
      "[2021-10-27 21:16:01,172 WARNING] Empty line exists in corpus_1#25093.\n",
      "[2021-10-27 21:16:01,181 WARNING] Empty line exists in corpus_1#25548.\n",
      "[2021-10-27 21:16:01,184 WARNING] Empty line exists in corpus_1#25852.\n",
      "[2021-10-27 21:16:01,185 WARNING] Empty line exists in corpus_1#25925.\n",
      "[2021-10-27 21:16:01,193 WARNING] Empty line exists in corpus_1#26156.\n",
      "[2021-10-27 21:16:01,193 WARNING] Empty line exists in corpus_1#26217.\n",
      "[2021-10-27 21:16:01,211 WARNING] Empty line exists in corpus_1#26338.\n",
      "[2021-10-27 21:16:01,211 WARNING] Empty line exists in corpus_1#26340.\n",
      "[2021-10-27 21:16:01,211 WARNING] Empty line exists in corpus_1#26343.\n",
      "[2021-10-27 21:16:01,212 WARNING] Empty line exists in corpus_1#26345.\n",
      "[2021-10-27 21:16:01,212 WARNING] Empty line exists in corpus_1#26381.\n",
      "[2021-10-27 21:16:01,213 WARNING] Empty line exists in corpus_1#26392.\n",
      "[2021-10-27 21:16:01,253 WARNING] Empty line exists in corpus_1#27358.\n",
      "[2021-10-27 21:16:01,253 WARNING] Empty line exists in corpus_1#27359.\n",
      "[2021-10-27 21:16:01,322 WARNING] Empty line exists in corpus_1#29600.\n",
      "[2021-10-27 21:16:01,322 WARNING] Empty line exists in corpus_1#29624.\n",
      "[2021-10-27 21:16:01,368 WARNING] Empty line exists in corpus_1#29706.\n",
      "[2021-10-27 21:16:01,388 WARNING] Empty line exists in corpus_1#30267.\n",
      "[2021-10-27 21:16:01,422 WARNING] Empty line exists in corpus_1#30711.\n",
      "[2021-10-27 21:16:01,427 WARNING] Empty line exists in corpus_1#30961.\n",
      "[2021-10-27 21:16:01,427 WARNING] Empty line exists in corpus_1#30962.\n",
      "[2021-10-27 21:16:01,483 WARNING] Empty line exists in corpus_1#32704.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ronald/anaconda3/bin/onmt_train\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/onmt/bin/train.py\", line 172, in main\n",
      "    train(opt)\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/onmt/bin/train.py\", line 159, in train\n",
      "    train_process(opt, device_id=-1)\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/onmt/train_single.py\", line 109, in main\n",
      "    trainer.train(\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/onmt/trainer.py\", line 242, in train\n",
      "    self._gradient_accumulation(\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/onmt/trainer.py\", line 420, in _gradient_accumulation\n",
      "    self.optim.step()\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/onmt/utils/optimizers.py\", line 367, in step\n",
      "    self._optimizer.step()\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\", line 107, in step\n",
      "    F.adam(params_with_grad,\n",
      "  File \"/home/ronald/anaconda3/lib/python3.8/site-packages/torch/optim/_functional.py\", line 98, in adam\n",
      "    param.addcdiv_(exp_avg, denom, value=-step_size)\n",
      "RuntimeError: output with shape [512] doesn't match the broadcast shape [512, 512]\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config toy_en_de.yaml --train_from uncorpus-fren-subword-transformer-model_step_200000.pt --continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6558d4-0192-4ef4-b229-6c6ab08c7bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47af8f9-0743-4be4-9203-9dc215f96564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
